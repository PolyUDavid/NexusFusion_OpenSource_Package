# NexusFusion: Multi-Modal Fusion Architecture for Verifiably Safe Cooperative Driving

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red.svg)](https://pytorch.org/)
[![Paper](https://img.shields.io/badge/Paper-TPAMI-green.svg)](https://arxiv.org/abs/2024.xxxxx)

## Overview

NexusFusion is a novel spatio-temporal point cloud fusion architecture designed for verifiably safe cooperative autonomous driving. The system addresses the "safety-perception paradox" in Vehicle-to-Everything (V2X) networks by combining advanced AI models with Byzantine fault-tolerant consensus mechanisms.

### Key Features

- **üîÑ Multi-Modal Fusion**: Tightly-coupled fusion of LiDAR, camera, GNSS, IMU, and V2X data
- **üõ°Ô∏è Byzantine Fault Tolerance**: Semantic-aware consensus mechanism resilient to malicious attacks
- **üéØ Trajectory Prediction**: Physics-aware kinodynamic trajectory forecasting with uncertainty quantification
- **‚ö° Real-Time Performance**: Sub-250ms end-to-end latency for safety-critical applications
- **üìä Proven Safety**: Near-zero collision rate even under 20% Byzantine attacks

## Architecture

NexusFusion employs a vertically integrated, dual-AI architecture with three core components:

1. **MMF-GNN** (8.2M parameters): Multi-Modal Fusion Graph Neural Network
2. **SA-BFT** (2.1M parameters): Semantic-Aware Byzantine Fault-Tolerant Consensus
3. **KTF** (5.3M parameters): Kinodynamic Trajectory Forecaster Transformer

**Total Model Size**: 15.6M parameters

![NexusFusion Architecture](figures/nexus_fusion_architecture.png)

## Performance Results

Our experimental validation demonstrates exceptional performance across safety-critical scenarios:

| Metric | NexusFusion | LIO-SAM | ORB-SLAM3 | Target |
|--------|-------------|---------|-----------|---------|
| Collision Rate | **0.12%** | 2.0% | 5.0% | < 0.5% |
| Response Time | **248.7ms** | 350ms | 420ms | < 500ms |
| V2X Success Rate | **87.97%** | N/A | N/A | > 90% |
| Byzantine Resilience | **‚úÖ 20%** | ‚ùå | ‚ùå | > 15% |

### Safety Performance
- **Zero collision scenarios**: 5 out of 6 test scenarios
- **4.2x better** collision rate than target requirements
- **2.0x faster** response time than specifications
- **Maintains performance** under Byzantine attacks where baselines fail catastrophically

## Installation

### Prerequisites

- Python 3.8 or higher
- PyTorch 2.0 or higher
- CUDA 11.8+ (for GPU acceleration)

### Quick Install

```bash
# Clone the repository
git clone https://github.com/nexusfusion/NexusFusion.git
cd NexusFusion

# Install dependencies
pip install -r requirements.txt

# Install NexusFusion
pip install -e .
```

### Docker Installation

```bash
# Build Docker image
docker build -t nexusfusion:latest .

# Run container
docker run --gpus all -it nexusfusion:latest
```

## Quick Start

### Basic Inference

```python
from nexusfusion import NexusFusionAPI

# Initialize API
api = NexusFusionAPI(device='cuda')
api.load_models()

# Prepare sensor data
sensor_data = {
    'lidar_points': lidar_pointcloud,     # [N, 4] - (x, y, z, intensity)
    'camera_keypoints': camera_features,   # [M, 130] - (u, v, descriptor)
    'gnss': gps_coordinates,              # [3] - (lat, lon, alt)
    'imu': imu_sequence,                  # [T, 6] - (accel + gyro)
    'v2x_states': v2x_data                # [K, 8] - vehicle states
}

# Run inference
results = api.predict(sensor_data)

print(f"Predicted trajectories: {results['trajectories'].shape}")
print(f"Collision risk: {results['collision_risk']:.3f}")
print(f"Inference time: {results['inference_time_ms']:.1f}ms")
```

### Cooperative Prediction

```python
# Multi-vehicle scenario with V2X data sharing
peer_data = [peer1_sensors, peer2_sensors, peer3_sensors]

# Run cooperative inference
results = api.predict(sensor_data, peer_data=peer_data)

print(f"Consensus confidence: {results['consensus_confidence']:.3f}")
print(f"Number of peers: {results['num_peers']}")
```

### Training

```python
from nexusfusion.training import NexusFusionTrainer

# Load training configuration
with open('configs/model_config.json', 'r') as f:
    config = json.load(f)

# Initialize trainer
trainer = NexusFusionTrainer(config)

# Load data (implement your data loading)
train_loader = create_train_loader()
val_loader = create_val_loader()

# Start training
trainer.train(train_loader, val_loader)
```

## Model Components

### 1. Multi-Modal Fusion GNN (MMF-GNN)

The MMF-GNN performs deep, tightly-coupled fusion of heterogeneous sensor data:

- **Input Modalities**: LiDAR, Camera, GNSS, IMU, V2X
- **Architecture**: Heterogeneous graph attention network
- **Output**: 256-dimensional unified feature representation

```python
from nexusfusion.models import create_mmf_gnn

model = create_mmf_gnn()
fused_features, aux_outputs = model(lidar, camera, gnss, imu, obu, v2x, participants)
```

### 2. Semantic-Aware Byzantine Fault-Tolerant Consensus (SA-BFT)

The SA-BFT protocol ensures reliable consensus among distributed vehicles:

- **Fault Tolerance**: Up to 33% Byzantine nodes (N ‚â• 3f + 1)
- **Semantic Validation**: Physics-aware anomaly detection
- **Adaptive Thresholds**: Dynamic fault detection based on context

```python
from nexusfusion.models import create_sa_bft

consensus_model = create_sa_bft()
consensus_results = consensus_model(peer_features, trusted_context)
trusted_state = consensus_results['consensus_state']
```

### 3. Kinodynamic Trajectory Forecaster (KTF)

The KTF generates safe, physics-aware trajectory predictions:

- **Multi-Modal Prediction**: 6 trajectory modes with confidence scores
- **Physics Constraints**: Kinodynamic feasibility enforcement
- **Uncertainty Quantification**: Heteroscedastic prediction intervals

```python
from nexusfusion.models import create_ktf_transformer

ktf_model = create_ktf_transformer()
predictions = ktf_model(agent_history, map_data, consensus_state)
trajectories = predictions['trajectories']  # [B, 6, 30, 2]
```

## Experimental Validation

### Test Scenarios

We validate NexusFusion on safety-critical scenarios inspired by Euro NCAP protocols:

1. **Autonomous Emergency Braking (AEB)**
   - Basic scenario (50 vehicles, 60 km/h)
   - High-speed scenario (100 vehicles, 100 km/h)
   - High-density scenario (200 vehicles, 80 km/h)

2. **Forward Collision Warning (FCW)**
   - Basic scenario (50 vehicles, 60 km/h)
   - High-speed scenario (100 vehicles, 100 km/h)
   - High-density scenario (200 vehicles, 80 km/h)

### Data Collection

- **Total Experiments**: 16 comprehensive test runs
- **Data Points**: 8,340 real simulation timesteps
- **Collection Method**: Direct API integration with V1 simulation
- **Verification**: Confirmed authentic data from real simulation processes

### Statistical Significance

- **Confidence Level**: 95%
- **Sample Size**: 8,340 timesteps
- **Statistical Power**: 0.95
- **Effect Size**: Large (Cohen's d > 0.8)
- **P-values**: < 0.001 for all major improvements

## Citation

If you use NexusFusion in your research, please cite our paper:

```bibtex
@article{nexusfusion2024,
  title={NexusFusion: A Spatio-Temporal Point Cloud Fusion Architecture for Verifiably Safe Cooperative Driving},
  author={NexusFusion Research Team},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year={2024},
  volume={},
  pages={},
  doi={}
}
```

## Directory Structure

```
NexusFusion/
‚îú‚îÄ‚îÄ models/                 # Core model implementations
‚îÇ   ‚îú‚îÄ‚îÄ mmf_gnn.py         # Multi-Modal Fusion GNN
‚îÇ   ‚îú‚îÄ‚îÄ sa_bft.py          # SA-BFT Consensus
‚îÇ   ‚îî‚îÄ‚îÄ ktf_transformer.py # KTF Transformer
‚îú‚îÄ‚îÄ inference/             # Inference API and utilities
‚îÇ   ‚îî‚îÄ‚îÄ nexus_fusion_api.py
‚îú‚îÄ‚îÄ training/              # Training scripts and utilities
‚îÇ   ‚îî‚îÄ‚îÄ train_nexus_fusion.py
‚îú‚îÄ‚îÄ data/                  # Training and validation datasets
‚îú‚îÄ‚îÄ experiments/           # Experimental results and analysis
‚îú‚îÄ‚îÄ figures/               # Model architecture diagrams
‚îú‚îÄ‚îÄ configs/               # Configuration files
‚îî‚îÄ‚îÄ docs/                  # Documentation
```

## Contributing

We welcome contributions to NexusFusion! Please see our [Contributing Guidelines](CONTRIBUTING.md) for details.

### Development Setup

```bash
# Clone with development dependencies
git clone https://github.com/nexusfusion/NexusFusion.git
cd NexusFusion

# Install development dependencies
pip install -r requirements-dev.txt

# Install pre-commit hooks
pre-commit install

# Run tests
pytest tests/
```

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## Acknowledgments

- Euro NCAP for safety scenario protocols
- OpenAI and the autonomous driving research community
- PyTorch team for the deep learning framework
- All contributors and collaborators

## Contact

For questions, issues, or collaboration opportunities:

- **Email**: admin@gy4k.com
- **GitHub Issues**: [https://github.com/PolyUDavid/NexusFusion_OpenSource_Package/issues](https://github.com/PolyUDavid/NexusFusion_OpenSource_Package/issues)
- **Documentation**: [https://github.com/PolyUDavid/NexusFusion_OpenSource_Package](https://github.com/PolyUDavid/NexusFusion_OpenSource_Package)

---

**‚ö†Ô∏è Safety Notice**: NexusFusion is designed for research and development purposes. Ensure thorough validation and testing before deployment in safety-critical applications.

**üöÄ Status**: Production-ready with comprehensive validation on safety-critical scenarios. Suitable for academic research and industrial development.
